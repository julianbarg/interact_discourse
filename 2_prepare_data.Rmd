---
date: "2022-11-08"
output: markdown
---

## Functions

```{r load, include=F}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(glue)
# library(SnowballC)
library(textstem)
library(tidytext)
library(tm)
options(max.print = 1000)
util_folder <- c("util")
beep <- function(){
  system(str_c("notify-send 'Task complete.'",
               "&& paplay /usr/share/sounds/Yaru/stereo/message.oga"))
}
```

## Input

```{r input}
metadata <- yaml::read_yaml(here("input", "metadata.yaml"))
known_entities <- yaml::read_yaml(here("input", "nlp_input.yaml")) %>%
  pluck("known_entities") %>%
  map_dfr(flatten_dfc) %>%
  {set_names(.$token, regex(.$regex, ignore_case = T))}
custom_stopwords <- yaml::read_yaml(here("input", "nlp_input.yaml")) %>%
  pluck("custom_stopwords")
known_entities
custom_stopwords
```

## Loader

```{r load}
source(here(util_folder, "load_data.R"))
source(here("input", "load_fixes.R"))
data <- metadata$index %>%
    map(read_data) %>%
    map(~ fixes[[.x$group]](.x))
glimpse(data[[11]])
```

## Tokenize

```{r tokenize}
source(here(util_folder, "tokenize.R"))
data_tokens <- data %>%
  map( ~ list_modify(.x, tokens = mutate(
    tokenize(.x$document, custom_stopwords, known_entities)
  )))
glimpse(data_tokens[1:2])
beep()
```

Sanity check

```{r test}
data_tokens[[11]]$tokens %>%
  filter(str_detect(token, "^tar sand|^oil sand"))
```

# Frequency

1. Infrequent

```{r infrequent}
low_freq <- 0.005
source(here(util_folder, "count_by_doc.R"))
source(here(util_folder, "get_frequency.R"))
frequency <- data_tokens %>%
  map_dfr(count_by_doc) %>%
  get_frequency()
infrequent <- frequency %>%
  filter(share < low_freq)
infrequent %>%
  arrange(desc(frequency), token)
data_frequent <- data_tokens %>%
  map(~ modify_at(.x, "tokens", ~ anti_join(.x, infrequent, by = "token")))
```

2. tfidf 

```{r tfidf}
tfidf_cutoff <- 0.001
source(here(util_folder, "prop_tfidf.R"))
source(here(util_folder, "remove_tfidf.R"))
tfidf <- data_frequent %>%
  map_dfr(count_by_doc) %>%
  prop_tfidf(tfidf_cutoff)
arrange(tfidf, desc(tf_idf))
high_tfidf_data <- data_frequent  %>%
  map(remove_tfidf, tfidf)
glimpse(high_tfidf_data[1:2])
```

Too frequent

```{r frequent_tokens}
too_frequent_cutoff <- 0.9
frequency_2 <- high_tfidf_data %>%
  map_dfr(count_by_doc) %>%
  get_frequency()
frequency_2 %>%
  arrange(desc(frequency))
frequent <- frequency_2 %>%
  filter(share > too_frequent_cutoff)
trimmed_data <- high_tfidf_data %>%
  map(~ modify_at(.x, "tokens", ~ anti_join(.x, frequent, by = "token")))
glimpse(trimmed_data[1:2])
```

## Count tokens

```{r count}
count_tokens <- function(df){
  df %>%
    group_by(order) %>%
    summarize(total_tokens = sum(n), .groups = "drop")
}
data_counted <- trimmed_data %>%
  map(~ list_modify(.x, token_counts = count_tokens(.x$tokens)))
glimpse(data_counted[[11]])
```

## Save

```{r save}
write_rds(data_counted, here("output", "trimmed_data.rds"))
```
